from transformers import T5Tokenizer
tokenizer = T5Tokenizer(vocab_file="t5-sp-bpe-nsmc-byte-fallback.model")
tokenizer.save_pretrained("t5-tokenizer-bpe-nsmc-byte-fallback")
lines = [
  "`DEVOCEAN`ì€ SKê·¸ë£¹ì˜ ëŒ€í‘œ ê°œë°œì ì»¤ë®¤ë‹ˆí‹°ì´ìğŸ§‘",
  "ë‚´/ì™¸ë¶€ ê°œë°œì ê°„ ì†Œí†µê³¼ ì„±ì¥ì„ ìœ„í•œ í”Œë«í¼ì„ ìƒì§•í•©ë‹ˆë‹¤.ğŸ‘‹",
  "`Developers`' Ocean ê°œë°œìë“¤ì„ ìœ„í•œ ì˜ê°ì˜ ë°”ë‹¤ğŸ™",
  "`Devotion` í—Œì‹ ,ëª°ë‘,ì „ë…ğŸ’¯",
  "`Technology for Everyone` ëª¨ë‘ë¥¼ ìœ„í•œ ê¸°ìˆ ğŸ‘",
  "ì•„ ë”ë¹™.. ì§„ì§œ ì§œì¦ë‚˜ë„¤ìš” ëª©ì†Œë¦¬",
  "í ...í¬ìŠ¤í„°ë³´ê³  ì´ˆë”©ì˜í™”ì¤„....ì˜¤ë²„ì—°ê¸°ì¡°ì°¨ ê°€ë³ì§€ ì•Šêµ¬ë‚˜",
  "ë„ˆë¬´ì¬ë°“ì—ˆë‹¤ê·¸ë˜ì„œë³´ëŠ”ê²ƒì„ì¶”ì²œí•œë‹¤",
  "êµë„ì†Œ ì´ì•¼ê¸°êµ¬ë¨¼ ..ì†”ì§íˆ ì¬ë¯¸ëŠ” ì—†ë‹¤..í‰ì  ì¡°ì •",
  "ì‚¬ì´ëª¬í˜ê·¸ì˜ ìµì‚´ìŠ¤ëŸ° ì—°ê¸°ê°€ ë‹ë³´ì˜€ë˜ ì˜í™”!ìŠ¤íŒŒì´ë”ë§¨ì—ì„œ ëŠ™ì–´ë³´ì´ê¸°ë§Œ í–ˆë˜ ì»¤ìŠ¤í‹´ ë˜ìŠ¤íŠ¸ê°€ ë„ˆë¬´ë‚˜ë„ ì´ë»ë³´ì˜€ë‹¤"
  ]

for line in lines:
    tokens = tokenizer.tokenize(line)
    inputs = tokenizer(line)    
    decoded_sequence = tokenizer.decode(inputs['input_ids'])
    print(line)
    print(tokens)    
    print(decoded_sequence)
    print()
